### visualiza mic y FFT y muestras  en tiempo real. Se procesa la señal y se agregan efectos de distorsión.


import matplotlib
import matplotlib.pyplot as plt
import pyaudio as pa 
import struct 
import scipy.fftpack as fourier
import numpy as np
import sounddevice as sd


matplotlib.use('TkAgg')
p = pa.PyAudio()

FRAMES = 1024*8                                   # Tamaño del paquete a procesar
FORMAT = pa.paInt16                               # Formato de lectura INT 16 bits
CHANNELS = 1
Fs = 44100                                        # Frecuencia de muestreo típica para audio


## Creamos una gráfica con 2 subplots y configuramos los ejes

fig, (ax,ax1) = plt.subplots(2)
x_audio = np.arange(0,FRAMES,1)
x_fft = np.linspace(0, Fs, FRAMES)
line, = ax.plot(x_audio, np.random.rand(FRAMES),'r')
line_fft, = ax1.semilogx(x_fft, np.random.rand(FRAMES), 'b')
#line_fft, = ax1.plot(x_fft, np.random.rand(FRAMES), 'b')
ax.set_ylim(-32500,32500)
ax.set_xlim = (0,FRAMES)
Fmin = 1
Fmax = 5000
ax1.set_xlim(Fmin,Fmax)
F = (Fs/FRAMES)*np.arange(0,FRAMES//2)                 # Creamos el vector de frecuencia para encontrar la frecuencia dominante

fig.show()
stream_active = True




def callback(in_data, frame_count, time_info, status):
    dataInt = struct.unpack(str(FRAMES) + 'h', in_data)  # Convertimos los datos que se encuentran empaquetados en bytes
  

    #if stream_active:
    #    sd.write('segmento_grabado.wav', np.array(dataInt), Fs)
        #stream_active = False

   # Proceso los datos de audio aquí
    x = np.linspace(0, len(dataInt)/Fs, len(dataInt))  # Genera un vector de tiempo de 0 a 1
    freq_fun = 2200 * 2 * np.pi  # Frecuencia de la señal seno (ejemplo: 440 Hz)
    seno = np.cos(x * freq_fun)  # Genera una señal seno
    
    # Suma la señal seno a los datos de entrada
    dataFloat32 = np.array(dataInt, dtype=np.float32)
    data_normalized = dataFloat32/np.max(np.abs(dataFloat32))
    data_modulated = data_normalized * seno # se hace modulación multiplicando la señal de entrada con un coseno
    
    data_desnorm = data_modulated * np.max(np.abs(dataFloat32)) # se desnormaliza la señal si es necesario.
    dataFloat32 = data_desnorm
    # Convierte nuevamente los datos a enteros antes de escribirlos en el stream
    dataInt = dataFloat32.astype(np.int16)
    
    
    
    line.set_ydata(dataInt)                            # Asignamos los datos a la curva de la variación temporal
    M_gk = abs(fourier.fft(dataInt)/FRAMES)            # Calculamos la FFT y la Magnitud de la FFT del paqute de datos
    ax1.set_ylim(0,np.max(M_gk+10)) 
    line_fft.set_ydata(M_gk)                           # Asigmanos la Magnitud de la FFT a la curva del espectro 
    M_gk = M_gk[0:FRAMES//2]                           # Tomamos la mitad del espectro para encontrar la Frecuencia Dominante
  #  Posm = np.where(M_gk == np.max(M_gk))
  #  F_fund = F[Posm]                                   # Encontramos la frecuencia que corresponde con el máximo de M_gk
    
    #print(int(F_fund))                                 # Imprimimos el valor de la frecuencia dominante
    
    output_stream.write(struct.pack(f'{len(dataInt)}h', *dataInt))  # Escribe los datos en el stream de salida
    #sd.write('segmento_grabado.wav', np.array(dataInt), Fs)

#    output_stream.write(in_data)
    
    return (in_data, pa.paContinue)


def stop_stream(event):
    global stream_active
    if stream_active:
        input_stream.stop_stream()
        #input_stream.close()
        output_stream.stop_stream()
        #output_stream.close()
        #p.terminate()
        stream_active = False

def restart_stream(event):
    global stream_active
    if not stream_active:
        input_stream.start_stream()
        output_stream.start_stream()
        stream_active = True


input_stream = p.open(                                  # Abrimos el canal de audio con los parámeteros de configuración
    format = FORMAT,
    channels = CHANNELS,
    rate = Fs,
    input=True,
    output=False,
    frames_per_buffer=FRAMES,
    stream_callback = callback,
    )

output_stream = p.open(                                  # Abrimos el canal de audio con los parámeteros de configuración
    format = FORMAT,
    channels = CHANNELS,
    rate = Fs,
    input=False,
    output=True,
    frames_per_buffer=FRAMES,
)
    
btn_stop_ax = plt.axes([0.01, 0.92, 0.1, 0.075])  # Coordenadas y tamaño del botón
btn_restart_ax = plt.axes([0.12, 0.92, 0.1, 0.075])

btn_stop = plt.Button(btn_stop_ax, 'Detener')
btn_stop.on_clicked(stop_stream)

btn_restart = plt.Button(btn_restart_ax, 'Reiniciar')
btn_restart.on_clicked(restart_stream)

input_stream.start_stream()
output_stream.start_stream()
stream_active = True

while True:
        
    try:
        fig.canvas.draw()
        fig.canvas.flush_events()
    except (KeyboardInterrupt, SystemExit):
        break
    
